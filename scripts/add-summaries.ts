import fs from "fs";
import path from "path";
import matter from "gray-matter";
import OpenAI from "openai";
import { config } from "dotenv";

// .env.local íŒŒì¼ ë¡œë“œ (ì—†ìœ¼ë©´ .env íŒŒì¼ ì‹œë„)
const envPath = path.join(process.cwd(), ".env.local");
if (fs.existsSync(envPath)) {
  config({ path: envPath });
} else {
  // .env.localì´ ì—†ìœ¼ë©´ .env íŒŒì¼ ì‹œë„
  config();
}

// OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ì½˜í…ì¸  ë””ë ‰í† ë¦¬ ê²½ë¡œ
const CONTENT_DIR = path.join(process.cwd(), "content");

// ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
function getMarkdownFiles(dir: string): string[] {
  return fs
    .readdirSync(dir)
    .filter(
      (file) => path.extname(file) === ".mdx" || path.extname(file) === ".md"
    )
    .map((file) => path.join(dir, file));
}

// ë³¸ë¬¸ì—ì„œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
function stripMarkdown(content: string): string {
  return content
    .replace(/^#+\s+/gm, "") // í—¤ë” ì œê±°
    .replace(/\*\*(.*?)\*\*/g, "$1") // ë³¼ë“œ ì œê±°
    .replace(/\*(.*?)\*/g, "$1") // ì´íƒ¤ë¦­ ì œê±°
    .replace(/\[([^\]]+)\]\([^\)]+\)/g, "$1") // ë§í¬ ì œê±°
    .replace(/```[\s\S]*?```/g, "") // ì½”ë“œ ë¸”ë¡ ì œê±°
    .replace(/`([^`]+)`/g, "$1") // ì¸ë¼ì¸ ì½”ë“œ ì œê±°
    .replace(/^\s*[-*+]\s+/gm, "") // ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ ì œê±°
    .replace(/^\s*\d+\.\s+/gm, "") // ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ì œê±°
    .replace(/\n{3,}/g, "\n\n") // ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
    .trim();
}

// OpenAIë¡œ í•œì¤„ ìš”ì•½ ìƒì„±
async function generateSummary(
  content: string,
  model: string = "gpt-3.5-turbo"
): Promise<string> {
  const strippedContent = stripMarkdown(content);

  // ì½˜í…ì¸ ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ ê³ ë ¤, ë¹„ìš© ì ˆê°)
  // gpt-3.5-turboëŠ” ë” ì €ë ´í•˜ë¯€ë¡œ ê¸¸ì´ë¥¼ ë” ì¤„ì—¬ë„ ë¨
  const maxLength = model.includes("gpt-3.5") ? 2000 : 3000;
  const contentToSummarize =
    strippedContent.length > maxLength
      ? strippedContent.substring(0, maxLength) + "..."
      : strippedContent;

  try {
    const response = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: "system",
          content:
            "ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ í•œì¤„ë¡œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ìš”ì•½ì€ 100ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
        },
        {
          role: "user",
          content: `ë‹¤ìŒ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ í•œì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n${contentToSummarize}`,
        },
      ],
      temperature: 0.7,
      max_tokens: 100, // ì¶œë ¥ í† í° ì¤„ì—¬ì„œ ë¹„ìš© ì ˆê°
    });

    const summary = response.choices[0]?.message?.content?.trim() || "";
    return summary;
  } catch (error) {
    console.error("OpenAI API ì˜¤ë¥˜:", error);
    throw error;
  }
}

// íŒŒì¼ì— summary ì¶”ê°€
async function addSummaryToFile(
  filePath: string,
  forceUpdate: boolean = false,
  model: string = "gpt-3.5-turbo"
) {
  try {
    const fileContent = fs.readFileSync(filePath, "utf-8");
    const { data, content } = matter(fileContent);

    // ì´ë¯¸ summaryê°€ ìˆê³  forceUpdateê°€ falseë©´ ê±´ë„ˆë›°ê¸°
    if (data.summary && !forceUpdate) {
      console.log(`â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ summary ì¡´ì¬): ${path.basename(filePath)}`);
      return;
    }

    console.log(`ğŸ“ ìš”ì•½ ìƒì„± ì¤‘: ${path.basename(filePath)}`);

    // ìš”ì•½ ìƒì„±
    const summary = await generateSummary(content, model);

    // front matterì— summary ì¶”ê°€
    const updatedData = {
      ...data,
      summary,
    };

    // gray-matterë¥¼ ì‚¬ìš©í•´ì„œ front matter ì¬ìƒì„±
    const updatedContent = matter.stringify(content, updatedData);

    // íŒŒì¼ì— ì €ì¥
    fs.writeFileSync(filePath, updatedContent, "utf-8");

    console.log(`âœ… ì™„ë£Œ: ${path.basename(filePath)}`);
    console.log(`   ìš”ì•½: ${summary}\n`);

    // API í˜¸ì¶œ ê°„ ë”œë ˆì´ (rate limit ë°©ì§€)
    await new Promise((resolve) => setTimeout(resolve, 1000));
  } catch (error) {
    console.error(`âŒ ì˜¤ë¥˜ ë°œìƒ (${path.basename(filePath)}):`, error);
  }
}

// ë©”ì¸ í•¨ìˆ˜
async function main() {
  // OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ í™•ì¸
  if (!process.env.OPENAI_API_KEY) {
    console.error("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
    console.error(
      "   .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•´ì£¼ì„¸ìš”."
    );
    process.exit(1);
  }

  const files = getMarkdownFiles(CONTENT_DIR);
  const forceUpdate = process.argv.includes("--force");

  // ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: gpt-3.5-turbo, --model ì˜µì…˜ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)
  let model = "gpt-3.5-turbo"; // ê¸°ë³¸ê°’: ê°€ì¥ ì €ë ´í•œ ëª¨ë¸
  const modelIndex = process.argv.indexOf("--model");
  if (modelIndex !== -1 && process.argv[modelIndex + 1]) {
    model = process.argv[modelIndex + 1];
  }

  console.log(`ğŸ“š ì´ ${files.length}ê°œì˜ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.`);
  console.log(`ğŸ¤– ì‚¬ìš© ëª¨ë¸: ${model}`);
  console.log(
    `ğŸ’° ì˜ˆìƒ ë¹„ìš©: ì•½ $0.001 ~ $0.002 per íŒŒì¼ (gpt-3.5-turbo ê¸°ì¤€)\n`
  );

  for (const file of files) {
    await addSummaryToFile(file, forceUpdate, model);
  }

  console.log("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!");
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main().catch(console.error);
