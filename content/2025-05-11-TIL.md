---
title: 2025.05.11 TIL
subtitle: 포모도로 타이머 샀다
tags: [study, ai, prompt]
---

# Prompt Enginnering

- LLM이 prediction engine 라는 것을 생각해야함
  - 순차 문자열을 입력으로 받아서 학습한 데이터를 기반으로 예측값을 줌
  - 올바른 예측을 할 수 있도록 설정을 해주어야함

## LLM output configuration

### Output length

응답에서 생성할 토큰 수, 많을 수록 더 많은 계산을 해야함 (느린 응답, 비싼 비용)

### Sampling controls

여러 토큰을 예측하는데 어떤 토큰을 다음으로 선택할지 경정하는 것

- Temperature: 토큰 선택의 무작위성의 정도(the degree of randomness)를 조절함
  - 낮을 수록 정확한 선택, 높을 수록 예상치 못한 결과
- Top-K, Top-P (nucleus sampling): 다음 토큰이 상위 예측 확률을 가진 토큰에서 오는 것을 제한
  - Top-K: 가장 가능성이 높은 상위 K 토큰을 선택
  - Top-P: 누적 확률이 특정 값(P)을 초과하지 않는 상위 토큰을 선택
- Repetition Loop Bug: 반복되는 filler word로 응답이 채워지는 것. 적절하지 않은 temperature, top-k/top-p 설정으로 발생함

## Prompting Techniques

- LLM은 많은 데이터로 학습하지만 정확하지 않음. 특정 기술을 사용하면 더 좋은 답을 얻을 수 있다.

### Gneral prompting / zero shot

- zero shot으 가장 간단한 타입의 프롬프트, 작업에 대한 하나의 설명과 LLM을 시작하기 위한 몇개의 문자
  - 예시 없음을 의미함
- zero shot이 동작하지 않으면 "one-shot", "few-shot" 이라고 불리는 예시가 포함된 프롬프트 기술을 사용해야할 수 있음

### One-shot & few-shot

- one-shot: 한개의 예제 제공
- few-shot: 여러개의 예제 제공, one-shot과 비슷하지만 여러개의 예제가 모델이 패턴을 따르도록 함
- 다양한 입력에 강력한 출력을 원하면 여러 엣지 케이스를 예제에 포함하는 것이 중요함

### System, contextual and role prompting

- System prompting: 전반적인 맥락과 목적을 설정
  - 모델의 기본 기능과 전반적인 목적을 정의
  - 출력이 특정 조건(ex. JSON format)을 만족해야할 때 좋음
  - safety와 toxicity를 설정하기 좋음, ex. You sholud be respectful in your answer.
- Contextual prompting: 현재 작업과 관련된 세부 사항, 배경 정보를 제공
  - 즉각적인 정보를 제공, 동적인 작업에 특화되어있음
  - 내 요청을 더 빨리 이해할 수 있음
- Role prompting: 특정 역할이나 정체성을 부여
  - specificity와 personality를 부여함
  - 더 관련성 있고 유익한 출력을 생성하는데 좋음

### Step-back prompting

- 일반적인 질문을 먼저하고, 그 답을 작업에 대한 후속 프롬프트에 공급하여 성능을 향상시키는 기술
- 특정 질문만 하면 발생할 수 있는 편견을 완화할 수 있음

### Chain of Thought (CoT)

- 중간 추론 단계를 생성하여 LLM의 추론 능력을 향상시키는 기술
- 적은 노력으로 기성 LLM에 효과적이고 잘 동작함
- 중간 단계를 알기 때문에 잘못된 응답을 얻었을 때 분석할 수 있음
- 여러 LLM 간의 차이를 줄일 수 있음
- 더 많은 비용, 시간이 필요함

### Self-consistency

- 표본 추출과 다수결을 결합하여 다양한 추론 경로를 생성하고 가장 일관된 답변을 선택함
  - CoT는 greedy decoding 라서 효과에 한계가 있음
- 다음 단계를 수행함
  - 다양한 추론 생성
  - 생성된 응답에서 답 추출
  - 가장 일반적인 답 선택
- 예제에서는 여러개의 CoT를 만들고 그 중에서 선택하도록 함

### Tree of Thoughts (ToT)

- CoT의 일반화된 버전, LLM이 다양한 추론 경로를 동시에 탐색할 수 있게 함

### ReAct (reason & act)

- 자연어와 외부 도구를 사용하여 복잡한 작업을 수행하기 위한 패러다임
- 외부 API와 상호작용 하는 등의 액션을 함
- 현실 셰계에서 사람이 작업하는 것을 모방함
- 추론과 행동을 사고-행동 루프 (thought-action loop)로 결합하여 동작함
- 첫번쨰 추론에 대한 계핵을 만들고 실행하고, 결과를 관측하여 추론과 계획을 수정하는 과정을 반복함

### Automatic Prompt Engineering

- 프롬프트를 쓰는 것은 꽤 복잡한 일임, 그렇기 때문에 자동화해보자는 생각
- 프롬프트를 만들기 위한 프롬프트

## Best Practices

1. 예시를 제공하라
2. 단순하게 만들어라
3. 출력을 구체적으로 명시하라
4. 제약 보다는 지침을 사용하라
5. 최대 토큰 개수를 조절하라
6. 프롬프트에 변수를 사용해라
7. 여러 입력 형식과 글쓰기 스타일을 시도해라
8. 여러 분류 작업을 할때는 예제를 섞어라
9. 모델 업데이트에 적응해라
10. 여러 출력 형식을 시도해라
11. JSON으로 만들어라
12. 스키마로 작업해라
13. 다른 엔지니어와 함께 시도해라
14. CoT Best pratices: CoT는 greedy decoding이기 떄문에 temperature를 0으로 해라
15. 프롬프트 시도를 문서화해라
